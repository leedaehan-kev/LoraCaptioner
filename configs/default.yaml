img_encoder_name: ViT-B/16
text_encdec_name: google/flan-t5-base

batch_size_per_gpu: 256
data_subset_size: -1

log_batch_interval: 10

lr: 0.0001
num_epochs: 8

lora_config:
  lora_alpha: 16
  lora_dropout: 0.1
  r: 8
  target_modules:
  - SelfAttention.q
  - SelfAttention.k
  - EncDecAttention.q
  - EncDecAttention.k
  - DenseReluDense.wi_0
  - DenseReluDense.wi_1
  - DenseReluDense.wo